/**
 * è¯åº“å¯¼å…¥è„šæœ¬
 * 
 * ä½¿ç”¨æ–¹æ³•:
 * npx ts-node --compiler-options '{"module":"commonjs"}' scripts/import-vocab.ts
 * 
 * æˆ–åœ¨å¼€å‘ç¯å¢ƒ:
 * npm run import-vocab
 */

import { createClient } from '@supabase/supabase-js';
import * as fs from 'fs';
import * as path from 'path';
import 'dotenv/config';

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!;
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY!;

if (!supabaseUrl || !supabaseServiceKey) {
    console.error('âŒ Missing Supabase credentials');
    process.exit(1);
}

const supabase = createClient(supabaseUrl, supabaseServiceKey);

interface VocabBookMeta {
    title: string;
    category: string;
    cefrLevel: string;
    description?: string;
}

async function importVocabBook(jsonFileName: string, meta: VocabBookMeta) {
    console.log(`\nğŸ“š å¼€å§‹å¯¼å…¥: ${meta.title}`);

    try {
        // è¯»å– JSON æ–‡ä»¶
        const filePath = path.join(process.cwd(), 'data', jsonFileName);
        const fileContent = fs.readFileSync(filePath, 'utf-8');
        const words = JSON.parse(fileContent);

        if (!Array.isArray(words)) {
            throw new Error('JSON file must contain an array');
        }

        console.log(`   ğŸ“„ è¯»å–åˆ° ${words.length} ä¸ªå•è¯`);

        // æå– bookId
        const bookId = words[0]?.bookId || jsonFileName.replace('.json', '');

        // æ£€æŸ¥è¯ä¹¦æ˜¯å¦å·²å­˜åœ¨
        const { data: existingBook } = await supabase
            .from('vocab_books')
            .select('id')
            .eq('book_id', bookId)
            .single();

        if (existingBook) {
            console.log(`   âš ï¸ è¯ä¹¦å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º`);
            return { success: true, bookId: existingBook.id, skipped: true };
        }

        // åˆ›å»ºè¯ä¹¦è®°å½•
        const { data: book, error: bookError } = await supabase
            .from('vocab_books')
            .insert({
                book_id: bookId,
                title: meta.title,
                word_count: words.length,
                cefr_level: meta.cefrLevel,
                category: meta.category,
                description: meta.description
            })
            .select('id')
            .single();

        if (bookError) {
            throw new Error(`åˆ›å»ºè¯ä¹¦å¤±è´¥: ${bookError.message}`);
        }

        console.log(`   âœ… è¯ä¹¦åˆ›å»ºæˆåŠŸ: ${book.id}`);

        // æ‰¹é‡æ’å…¥å•è¯ (æ¯æ‰¹ 100 ä¸ª)
        const batchSize = 100;
        let insertedCount = 0;

        for (let i = 0; i < words.length; i += batchSize) {
            const batch = words.slice(i, i + batchSize);

            const vocabWords = batch.map((word: any) => ({
                book_id: book.id,
                word_rank: word.wordRank,
                head_word: word.headWord,
                us_phonetic: word.content?.word?.content?.usphone || null,
                uk_phonetic: word.content?.word?.content?.ukphone || null,
                translations: word.content?.word?.content?.trans || null,
                sentences: word.content?.word?.content?.sentence?.sentences || null,
                real_exam_sentences: word.content?.word?.content?.realExamSentence?.sentences || null,
                synonyms: word.content?.word?.content?.syno?.synos || null,
                phrases: word.content?.word?.content?.phrase?.phrases || null,
                memory_method: word.content?.word?.content?.remMethod?.val || null,
                related_words: word.content?.word?.content?.relWord?.rels || null,
                picture_url: word.content?.word?.content?.picture || null,
                exams: word.content?.word?.content?.exam || null,
                raw_content: word
            }));

            const { error: insertError } = await supabase
                .from('vocab_words')
                .insert(vocabWords);

            if (insertError) {
                console.error(`   âŒ æ‰¹æ¬¡ ${i / batchSize + 1} æ’å…¥å¤±è´¥:`, insertError.message);
            } else {
                insertedCount += batch.length;
                process.stdout.write(`\r   ğŸ“¥ å·²å¯¼å…¥: ${insertedCount}/${words.length}`);
            }
        }

        console.log(`\n   âœ… å¯¼å…¥å®Œæˆ: ${insertedCount}/${words.length} ä¸ªå•è¯`);

        return {
            success: true,
            bookId: book.id,
            importedCount: insertedCount,
            totalCount: words.length
        };

    } catch (error: any) {
        console.error(`   âŒ å¯¼å…¥å¤±è´¥:`, error.message);
        return { success: false, error: error.message };
    }
}

// ä¸»å‡½æ•°
async function main() {
    console.log('ğŸš€ ENGRAM è¯åº“å¯¼å…¥å·¥å…·\n');
    console.log('='.repeat(50));

    // å¯¼å…¥ CET4 è¯åº“
    await importVocabBook('cet4-core-vocabulary.json', {
        title: 'å››çº§çœŸé¢˜æ ¸å¿ƒè¯',
        category: 'å››å…­çº§',
        cefrLevel: 'B1',
        description: 'å¤§å­¦è‹±è¯­å››çº§è€ƒè¯•æ ¸å¿ƒé«˜é¢‘è¯æ±‡ï¼ŒåŒ…å«çœŸé¢˜ä¾‹å¥å’Œç­”é¢˜æŠ€å·§'
    });

    // å¯¼å…¥ CET6 è¯åº“
    await importVocabBook('cet6-core-vocabulary.json', {
        title: 'å…­çº§çœŸé¢˜æ ¸å¿ƒè¯',
        category: 'å››å…­çº§',
        cefrLevel: 'B2',
        description: 'å¤§å­¦è‹±è¯­å…­çº§è€ƒè¯•æ ¸å¿ƒé«˜é¢‘è¯æ±‡ï¼ŒåŒ…å«çœŸé¢˜ä¾‹å¥å’Œç­”é¢˜æŠ€å·§'
    });

    console.log('\n' + '='.repeat(50));
    console.log('âœ… æ‰€æœ‰å¯¼å…¥ä»»åŠ¡å®Œæˆ!');
}

main().catch(console.error);
